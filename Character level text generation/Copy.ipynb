{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51f12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f79bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=open('./dinos.txt').read()\n",
    "data=data.lower()\n",
    "chars=sorted(list(set(data)))\n",
    "vocab_size=len(chars)\n",
    "print(chars)\n",
    "len(data.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050e1e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[e.strip() for e in data.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e49aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix={c:i for i,c in enumerate(chars)}\n",
    "ix_to_char={i:c for i,c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8aa1f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(gradients,maxval):\n",
    "    dWax=gradients['dWax']\n",
    "    dWya=gradients['dWya']\n",
    "    dWaa=gradients['dWaa']\n",
    "    dba=gradients['dba']\n",
    "    dby=gradients['dby']\n",
    "    \n",
    "    for grad in [dWax,dWya,dWaa,dba,dby]:\n",
    "        np.clip(grad,-maxval,maxval,out=grad)\n",
    "        \n",
    "    gradients['dWax']=dWax\n",
    "    gradients['dWya']=dWya\n",
    "    gradients['dWaa']=dWaa\n",
    "    gradients['dba']=dba\n",
    "    gradients['dby']=dby\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27db94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(parameters,max_size=30):\n",
    "    Waa=parameters['Waa']\n",
    "    Wax=parameters['Wax']\n",
    "    Wya=parameters['Wya']\n",
    "    ba=parameters['ba']\n",
    "    by=parameters['by']\n",
    "    \n",
    "    n_a=Waa.shape[0]\n",
    "    \n",
    "    x=np.zeros((vocab_size,1))\n",
    "    a_prev=np.zeros((n_a,1))\n",
    "    \n",
    "    indices=[]\n",
    "    idx=-1\n",
    "    \n",
    "    while(idx!=char_to_ix['\\n'] and len(indices)<=max_size):\n",
    "        a_t=np.tanh(np.dot(Wax,x)+np.dot(Waa,a_prev)+ba)\n",
    "        y=softmax(np.dot(Wya,a_t)+by)\n",
    "        \n",
    "        a_prev=a_t\n",
    "        \n",
    "        idx=np.random.choice(np.arange(len(y.ravel())),p=y.ravel())\n",
    "        indices.append(idx)\n",
    "        \n",
    "        x=np.zeros((vocab_size,1))\n",
    "        x[idx]=1\n",
    "    \n",
    "    if len(indices)>max_size:\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "    \n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c0cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X,Y,parameters,a_prev,lr):\n",
    "    loss,cache=rnn_forward(X,Y,parameters,a_prev)\n",
    "    \n",
    "    gradients,a=rnn_backward(X,Y,parameters,cache)\n",
    "    \n",
    "#     print(\"Gradients after backward pass:\")\n",
    "#     for key, value in gradients.items():\n",
    "#         print(f\"{key}: {value}\")\n",
    "    \n",
    "    gradients=clip(gradients,5)\n",
    "    \n",
    "#     print(\"Gradients after clipping:\")\n",
    "#     for key, value in gradients.items():\n",
    "#         print(f\"{key}: {value}\")\n",
    "    \n",
    "    parameters=update_parameters(parameters,gradients,lr)\n",
    "    \n",
    "    return loss,a[:,len(X)].reshape(-1,1),parameters,gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be2ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data,char_to_ix,ix_to_char,epochs=22000,learning_rate=0.01,n_a=64,sampling_size=7,vocab_size=27):\n",
    "    n_x,n_y=vocab_size,vocab_size\n",
    "    \n",
    "    parameters=initialize(n_x,n_a,n_y)\n",
    "    \n",
    "    examples=[e.strip() for e in data]\n",
    "    \n",
    "    a_prev=np.zeros((n_a,1))\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        example_i=examples[i%len(examples)]\n",
    "        \n",
    "        single_example=[char_to_ix[c] for c in example_i]\n",
    "        X=[None]+single_example\n",
    "        \n",
    "        Y=single_example+[char_to_ix['\\n']]\n",
    "        \n",
    "        loss,a_prev,parameters,gradients=optimize(X,Y,parameters,a_prev,learning_rate)\n",
    "        \n",
    "        if i%2000==0:\n",
    "            print(f'Current iteration: {i} Current loss {loss}')\n",
    "            for j in range(sampling_size):\n",
    "                sampled_indices=sample(parameters)\n",
    "                word=get_sampled_indices(sampled_indices,ix_to_char)\n",
    "                print(word.replace('\\n',''))\n",
    "            print('\\n')\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "186d1d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration: 0 Current loss 46.139977228199065\n",
      "Pdgfbgklxvgermxrcwvihvmxotbnyla\n",
      "Qvivxkhok\n",
      "C\n",
      "R\n",
      "Oedpmsjcivjqobtp\n",
      "Diekudqzvetobjujrs\n",
      "Ushpvplojyj\n",
      "\n",
      "\n",
      "Current iteration: 2000 Current loss 28.42074870746157\n",
      "Orlolonaus\n",
      "Kraptur\n",
      "Ros\n",
      "Paptosaurus\n",
      "Keros\n",
      "\n",
      "Ymomourus\n",
      "\n",
      "\n",
      "Current iteration: 4000 Current loss 25.262555742584038\n",
      "Us\n",
      "Tosaurus\n",
      "Iangoidene\n",
      "Oraman\n",
      "Homutopn\n",
      "Laoceaceor\n",
      "Sanblongops\n",
      "\n",
      "\n",
      "Current iteration: 6000 Current loss 26.23057348957724\n",
      "Us\n",
      "Saurus\n",
      "Csamaiaur\n",
      "Tin\n",
      "Toggttacor\n",
      "Enditeratataonus\n",
      "On\n",
      "\n",
      "\n",
      "Current iteration: 8000 Current loss 12.837914680376004\n",
      "\n",
      "Cs\n",
      "Scigoulelopeunaprreuloobioslcor\n",
      "Rolnimus\n",
      "Bus\n",
      "Us\n",
      "S\n",
      "\n",
      "\n",
      "Current iteration: 10000 Current loss 23.241564695829474\n",
      "Lovindratrengis\n",
      "Leditvunylengsaurus\n",
      "Tuligurisaurus\n",
      "Perss\n",
      "Anchis\n",
      "Eroinesaurus\n",
      "Inmiss\n",
      "\n",
      "\n",
      "Current iteration: 12000 Current loss 47.90220700213956\n",
      "Saurus\n",
      "Saurus\n",
      "Addls\n",
      "Ri\n",
      "Lolristrinbjelhasidisaurus\n",
      "Ia\n",
      "Vin\n",
      "\n",
      "\n",
      "Current iteration: 14000 Current loss 31.43159923406772\n",
      "Gauaurus\n",
      "Candatataababiamkats\n",
      "Rahthahbavaebiia\n",
      "Lipaanosaurus\n",
      "Miatmaaabhabemahadraanitiavanos\n",
      "S\n",
      "Rianmarnodapkmrnaurus\n",
      "\n",
      "\n",
      "Current iteration: 16000 Current loss 29.11279260935173\n",
      "Iaphihyprypsophyhuris\n",
      "Nyhipheshysthokinonilonogoluned\n",
      "Herolipholiplodeyoshigrenyypoph\n",
      "Gyropholohylopyizyopelophos\n",
      "Saurus\n",
      "Eross\n",
      "Ilthyepphops\n",
      "\n",
      "\n",
      "Current iteration: 18000 Current loss 19.596146322885858\n",
      "Totatocornplotovotasaurus\n",
      "Orops\n",
      "Nodocodoplitoptetorodocaltasaur\n",
      "Ngus\n",
      "Lonotochar\n",
      "Mimanyproterua\n",
      "Padottvuenoptisaurus\n",
      "\n",
      "\n",
      "Current iteration: 20000 Current loss 28.010424789325704\n",
      "Saurus\n",
      "Niaubaigosaurus\n",
      "Cor\n",
      "Eratota\n",
      "Eryg\n",
      "Ingoncorikazumoumasaurus\n",
      "Hes\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters=model(data.split('\\n'),char_to_ix,ix_to_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
